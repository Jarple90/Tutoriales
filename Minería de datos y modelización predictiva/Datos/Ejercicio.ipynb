{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana de 'lat' es: 47.5745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de colocar el archivo en el mismo directorio o proporcionar la ruta completa.\n",
    "\n",
    "# Calcula la mediana de la columna \"lat\"\n",
    "mediana_lat = df['lat'].median()\n",
    "print(f\"La mediana de 'lat' es: {mediana_lat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de valores únicos en 'condition' es: 5\n"
     ]
    }
   ],
   "source": [
    "valores_unicos = df['condition'].nunique()\n",
    "print(f\"El número de valores únicos en 'condition' es: {valores_unicos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de instancias que pertenecen a la categoría 0 de 'waterfront' es: 4852\n"
     ]
    }
   ],
   "source": [
    "cantidad_categoria_0 = df[df['waterfront'] == 0].shape[0]\n",
    "print(f\"La cantidad de instancias que pertenecen a la categoría 0 de 'waterfront' es: {cantidad_categoria_0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de filas faltantes en 'waterfront' es: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Calcula el porcentaje de valores faltantes en la columna 'waterfront'\n",
    "porcentaje_faltantes = (df['waterfront'].isnull().sum() / len(df)) * 100\n",
    "print(f\"El porcentaje de filas faltantes en 'waterfront' es: {porcentaje_faltantes:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.03\n",
      "Valor p de Ljung-Box: 1.623e-22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('IPI_Esp.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Limpiar la columna 'Date' para eliminar espacios adicionales\n",
    "df['Date'] = df['Date'].str.strip()  # Eliminar espacios antes y después de los valores\n",
    "\n",
    "# Reemplazar el formato '1975M01' a '1975-01'\n",
    "df['Date'] = df['Date'].str.replace('M', '-')  # Reemplazar 'M' por '-'\n",
    "\n",
    "# Convertir la columna 'Date' a formato datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m', errors='coerce')  # Manejo de errores para filas mal formateadas\n",
    "\n",
    "# Verificar si hay fechas no convertidas\n",
    "if df['Date'].isna().sum() > 0:\n",
    "    print(\"Advertencia: Existen fechas no convertidas correctamente.\")\n",
    "    print(df[df['Date'].isna()])  # Mostrar las filas problemáticas\n",
    "\n",
    "# Dividir el conjunto de datos en ventanas de entrenamiento y prueba\n",
    "train = df[df['Date'] <= '2017-12-31']  # Datos hasta el 31 de diciembre de 2017 (entrenamiento)\n",
    "test = df[df['Date'] > '2017-12-31']    # Datos desde el 1 de enero de 2018 (prueba)\n",
    "\n",
    "# Ajustar el modelo aditivo de Holt-Winters\n",
    "model = ExponentialSmoothing(\n",
    "    train['IPI Nacional'],  # Cambia 'IPI Nacional' si la columna tiene otro nombre\n",
    "    seasonal='add',         # Estacionalidad aditiva\n",
    "    seasonal_periods=12,    # Periodo estacional (mensual)\n",
    "    trend='add'             # Tendencia aditiva\n",
    ").fit()\n",
    "\n",
    "# Predicción en la ventana de prueba\n",
    "forecast = model.forecast(len(test))\n",
    "\n",
    "# Cálculo del MAPE\n",
    "mape_value = MAPE(test['IPI Nacional'], forecast)  # Cambia 'IPI Nacional' si la columna tiene otro nombre\n",
    "print(f\"MAPE: {mape_value:.2f}\")\n",
    "\n",
    "# Test de Ljung-Box para los residuos\n",
    "ljung_box_pvalue = acorr_ljungbox(model.resid, lags=[12], return_df=True)['lb_pvalue'].iloc[0]\n",
    "print(f\"Valor p de Ljung-Box: {ljung_box_pvalue:.3e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarpl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\jarpl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.03\n",
      "Valor p de Ljung-Box: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('IPI_Esp.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Limpiar la columna 'Date' para eliminar espacios adicionales\n",
    "df['Date'] = df['Date'].str.strip()  # Eliminar espacios antes y después de los valores\n",
    "\n",
    "# Reemplazar el formato '1975M01' a '1975-01'\n",
    "df['Date'] = df['Date'].str.replace('M', '-')  # Reemplazar 'M' por '-'\n",
    "\n",
    "# Convertir la columna 'Date' a formato datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m', errors='coerce')\n",
    "\n",
    "# Verificar si hay fechas no convertidas\n",
    "if df['Date'].isna().sum() > 0:\n",
    "    print(\"Advertencia: Existen fechas no convertidas correctamente.\")\n",
    "    print(df[df['Date'].isna()])  # Mostrar las filas problemáticas\n",
    "\n",
    "# Configurar la columna 'Date' como índice\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Dividir el conjunto de datos en ventanas de entrenamiento y prueba\n",
    "train = df[df.index <= '2017-12-31']  # Datos hasta el 31 de diciembre de 2017 (entrenamiento)\n",
    "test = df[df.index > '2017-12-31']    # Datos desde el 1 de enero de 2018 (prueba)\n",
    "\n",
    "# Ajustar el modelo SARIMAX(1,1,1)(1,1,1)[12]\n",
    "model = SARIMAX(\n",
    "    train['IPI Nacional'],  # Cambia 'IPI Nacional' si la columna tiene otro nombre\n",
    "    order=(1, 1, 1),         # Parámetros SARIMA (p, d, q)\n",
    "    seasonal_order=(1, 1, 1, 12)  # Parámetros estacionales (P, D, Q, s)\n",
    ").fit(disp=False)\n",
    "\n",
    "# Generar predicciones\n",
    "forecast = model.forecast(steps=len(test))\n",
    "\n",
    "# Cálculo del MAPE\n",
    "mape_value = MAPE(test['IPI Nacional'], forecast)  # Cambia 'IPI Nacional' si la columna tiene otro nombre\n",
    "print(f\"MAPE: {mape_value:.2f}\")\n",
    "\n",
    "# Test de Ljung-Box para los residuos\n",
    "ljung_box_pvalue = acorr_ljungbox(model.resid, lags=[12], return_df=True)['lb_pvalue'].iloc[0]\n",
    "print(f\"Valor p de Ljung-Box: {ljung_box_pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del archivo: Index(['year', 'month', 'price', 'Luxury', 'bedrooms', 'bathrooms',\n",
      "       'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n",
      "       'sqft_above', 'basement', 'yr_built', 'yr_renovated', 'lat', 'long'],\n",
      "      dtype='object')\n",
      "Valores únicos en la columna 'yr_renovated': [   0 2006 1983 1992 2001 2003 2009 2012 1989 1990 2007 1984 1955 2000\n",
      " 1995 2015 2014 2004 1978 1994 1977 1991 2002 1968 1965 1999 1987 1986\n",
      " 1996 1993 1979 1998 1985 1973 1970 2011 1988 2005 1976 1980 2010 1982\n",
      " 1971 2013 1972 1974 1967 2008 1960 1957 1953 1945 1964 1969 1997 1963\n",
      " 1950 1956]\n",
      "La cantidad de viviendas con 'yr_renovated' igual a 0 es: 4784\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo Excel llamado VentaViviendas.xlsx\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en la misma carpeta o proporciona la ruta completa.\n",
    "\n",
    "# Verificar las columnas del DataFrame para confirmar que 'yr_renovated' está presente\n",
    "print(\"Columnas del archivo:\", df.columns)\n",
    "\n",
    "# Limpiar espacios adicionales en los nombres de las columnas (si es necesario)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Verificar los valores únicos en 'yr_renovated' para asegurar consistencia\n",
    "print(\"Valores únicos en la columna 'yr_renovated':\", df['yr_renovated'].unique())\n",
    "\n",
    "# Contar las instancias donde 'yr_renovated' es igual a 0\n",
    "cantidad_cero = (df['yr_renovated'] == 0).sum()\n",
    "print(f\"La cantidad de viviendas con 'yr_renovated' igual a 0 es: {cantidad_cero}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del archivo: Index(['year', 'month', 'price', 'Luxury', 'bedrooms', 'bathrooms',\n",
      "       'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition',\n",
      "       'sqft_above', 'basement', 'yr_built', 'yr_renovated', 'lat', 'long'],\n",
      "      dtype='object')\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.091\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     498.6\n",
      "Date:                Wed, 19 Mar 2025   Prob (F-statistic):          2.30e-105\n",
      "Time:                        20:17:06   Log-Likelihood:                -71003.\n",
      "No. Observations:                5000   AIC:                         1.420e+05\n",
      "Df Residuals:                    4998   BIC:                         1.420e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept  -3.811e+07   1.73e+06    -22.016      0.000   -4.15e+07   -3.47e+07\n",
      "lat         8.128e+05   3.64e+04     22.330      0.000    7.41e+05    8.84e+05\n",
      "==============================================================================\n",
      "Omnibus:                     4955.287   Durbin-Watson:                   2.014\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           463864.478\n",
      "Skew:                           4.627   Prob(JB):                         0.00\n",
      "Kurtosis:                      49.270   Cond. No.                     1.64e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.64e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "El valor de R² es: 0.091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Verificar las columnas del archivo\n",
    "print(\"Columnas del archivo:\", df.columns)\n",
    "\n",
    "# Ajustar el modelo de regresión lineal con 'price' como precio\n",
    "modelo = smf.ols('price ~ lat', data=df).fit()\n",
    "\n",
    "# Obtener los resultados del modelo\n",
    "print(modelo.summary())\n",
    "\n",
    "# Imprimir el valor de R²\n",
    "r2 = modelo.rsquared\n",
    "print(f\"El valor de R² es: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media de sqft_living es: 2077.382\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Calcular la media de 'sqft_living'\n",
    "media_sqft_living = df['sqft_living'].mean()\n",
    "print(f\"La media de sqft_living es: {media_sqft_living:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La desviación típica de price es: 372986.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Calcular la desviación típica de 'price'\n",
    "desviacion_price = df['price'].std()\n",
    "print(f\"La desviación típica de price es: {desviacion_price:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de valores únicos en 'bedrooms' es: 33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Calcular el número de valores únicos en la columna 'bedrooms'\n",
    "valores_unicos = df['bedrooms'].nunique()\n",
    "print(f\"El número de valores únicos en 'bedrooms' es: {valores_unicos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de valores 'missing' en 'sqft_lot' (nulos, negativos o cero) es: 7.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Identificar valores considerados \"missing\" (nulos, negativos o igual a cero)\n",
    "missing_sqft_lot = df['sqft_lot'].isnull().sum()  # Valores nulos\n",
    "missing_negativos_cero = (df['sqft_lot'] <= 0).sum()  # Valores negativos o igual a cero\n",
    "\n",
    "# Total de valores missing\n",
    "total_missing = missing_sqft_lot + missing_negativos_cero\n",
    "\n",
    "# Calcular el porcentaje de valores \"missing\"\n",
    "total_filas = len(df)\n",
    "porcentaje_missing = (total_missing / total_filas) * 100\n",
    "\n",
    "print(f\"El porcentaje de valores 'missing' en 'sqft_lot' (nulos, negativos o cero) es: {porcentaje_missing:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.512\n",
      "Model:                            OLS   Adj. R-squared:                  0.512\n",
      "Method:                 Least Squares   F-statistic:                     5252.\n",
      "Date:                Wed, 19 Mar 2025   Prob (F-statistic):               0.00\n",
      "Time:                        20:32:50   Log-Likelihood:                -69445.\n",
      "No. Observations:                5000   AIC:                         1.389e+05\n",
      "Df Residuals:                    4998   BIC:                         1.389e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept   -6.105e+04   9127.245     -6.689      0.000   -7.89e+04   -4.32e+04\n",
      "sqft_living   291.3188      4.020     72.469      0.000     283.438     299.200\n",
      "==============================================================================\n",
      "Omnibus:                     3550.647   Durbin-Watson:                   1.992\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           156588.433\n",
      "Skew:                           2.877   Prob(JB):                         0.00\n",
      "Kurtosis:                      29.805   Cond. No.                     5.63e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.63e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "El parámetro estimado para el predictor 'sqft_living' es: 291.3188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Ajustar el modelo de regresión lineal\n",
    "modelo = smf.ols('price ~ sqft_living', data=df).fit()\n",
    "\n",
    "# Imprimir el resumen del modelo para ver el parámetro estimado\n",
    "print(modelo.summary())\n",
    "\n",
    "# Obtener el parámetro estimado para 'sqft_living'\n",
    "coef_sqft_living = modelo.params['sqft_living']\n",
    "print(f\"El parámetro estimado para el predictor 'sqft_living' es: {coef_sqft_living:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500003\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 Luxury   No. Observations:                 5000\n",
      "Model:                          Logit   Df Residuals:                     4998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 19 Mar 2025   Pseudo R-squ.:                  0.2660\n",
      "Time:                        20:33:55   Log-Likelihood:                -2500.0\n",
      "converged:                       True   LL-Null:                       -3405.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -4.1750      0.121    -34.420      0.000      -4.413      -3.937\n",
      "sqft_living     0.0019   5.67e-05     32.892      0.000       0.002       0.002\n",
      "===============================================================================\n",
      "El Odds Ratio estimado para 'sqft_living' es: 1.001866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('VentaViviendas.xlsx')  # Asegúrate de que el archivo esté en el mismo directorio o proporciona la ruta completa.\n",
    "\n",
    "# Ajustar el modelo de regresión logística\n",
    "modelo = smf.logit('Luxury ~ sqft_living', data=df).fit()\n",
    "\n",
    "# Imprimir el resumen del modelo\n",
    "print(modelo.summary())\n",
    "\n",
    "# Calcular el Odds Ratio para 'sqft_living'\n",
    "odds_ratio = np.exp(modelo.params['sqft_living'])\n",
    "print(f\"El Odds Ratio estimado para 'sqft_living' es: {odds_ratio:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas no convertidas: Empty DataFrame\n",
      "Columns: [Date, IPI Nacional]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarpl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\jarpl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.10\n",
      "Ljung-Box p-value: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('IPI_Esp.xlsx')  # Asegúrate de que el archivo esté disponible y su ruta sea correcta.\n",
    "\n",
    "# Limpiar espacios adicionales en la columna 'Date'\n",
    "df['Date'] = df['Date'].str.strip()\n",
    "\n",
    "# Convertir la columna 'Date' al formato datetime manejando el formato '1975M01'\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%YM%m', errors='coerce')\n",
    "\n",
    "# Verificar si hay fechas no convertidas\n",
    "print(\"Fechas no convertidas:\", df[df['Date'].isnull()])\n",
    "\n",
    "# Eliminar filas con fechas no convertidas (si existen)\n",
    "df = df.dropna(subset=['Date'])\n",
    "\n",
    "# Establecer la columna 'Date' como índice\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Dividir los datos en ventana de entrenamiento y prueba\n",
    "train = df[df.index <= '2017-12-31']\n",
    "test = df[df.index > '2018-01-01']\n",
    "\n",
    "# Ajustar el modelo SARIMAX(1,1,0)(1,1,0)[12]\n",
    "model = SARIMAX(\n",
    "    train['IPI Nacional'],  # Usando la columna 'IPI Nacional'\n",
    "    order=(1, 1, 0),\n",
    "    seasonal_order=(1, 1, 0, 12)\n",
    ").fit(disp=False)\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "forecast = model.forecast(steps=len(test))\n",
    "\n",
    "# Calcular el MAPE\n",
    "mape_value = MAPE(test['IPI Nacional'], forecast)\n",
    "print(f\"MAPE: {mape_value:.2f}\")\n",
    "\n",
    "# Prueba de Ljung-Box para los residuos\n",
    "ljung_box_pvalue = acorr_ljungbox(model.resid, lags=[12], return_df=True)['lb_pvalue'].iloc[0]\n",
    "print(f\"Ljung-Box p-value: {ljung_box_pvalue:.6f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
